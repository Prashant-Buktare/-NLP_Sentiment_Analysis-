{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import nltk\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the option  to display the entire text row\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is so selfish he drags his kids into his dysfunction.   #run</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't use cause they don't offer wheelchair vans in pdx.    #disapointed #getthanked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in urð??±!!! ð???ð???ð???ð???ð??¦ð??¦ð??¦</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label  \\\n",
       "0  1   0       \n",
       "1  2   0       \n",
       "2  3   0       \n",
       "3  4   0       \n",
       "4  5   0       \n",
       "\n",
       "                                                                                                                        tweet  \n",
       "0   @user when a father is dysfunctional and is so selfish he drags his kids into his dysfunction.   #run                      \n",
       "1  @user @user thanks for #lyft credit i can't use cause they don't offer wheelchair vans in pdx.    #disapointed #getthanked  \n",
       "2    bihday your majesty                                                                                                       \n",
       "3  #model   i love u take with u all the time in urð??±!!! ð???ð???ð???ð???ð??¦ð??¦ð??¦                                        \n",
       "4   factsguide: society now    #motivation                                                                                     "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the data set\n",
    "df_train=pd.read_csv(\"train_tweets.csv\",encoding=\"ISO-8859-1\")\n",
    "df_train.head()\n",
    "\n",
    "# There are three columns\n",
    "# 1: id\n",
    "# 2: label (1 and 0)\n",
    "# 3: tweet (text form)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31962, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape\n",
    "# 31962 rows and 3 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the frequency distribution\n",
    "df_train['label'].value_counts()\n",
    "# 29720 '0'\n",
    "# 2242 '1'\n",
    "zeroes_cnt=df_train['label'].value_counts()[0]\n",
    "ones_cnt=df_train['label'].value_counts()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the data set\n",
    "# creating the stop word list\n",
    "# Removing rows corresponding to stop word\n",
    "# Stop word removal using inbuilt and custom list\n",
    "from nltk.corpus import stopwords\n",
    "stop = set(stopwords.words('english'))\n",
    "stop2=list(stop)\n",
    "stop2.extend(['@user','@user @user','&amp;','@user @user @user','-','u','Ã¢Â€Â“',\n",
    "             'Ã¢Â€Â”','Ã¢Â€Â¦','Ã¢Â†Â','Ã¢ÂÂ¤','Ã¢ÂÂ¤Ã¯Â¸Â','Ã°ÂŸÂ’Â•','Ã°ÂŸÂ’Â¦Ã°ÂŸÂ’Â¦Ã°ÂŸÂ’Â¦',\n",
    "             'Ã°ÂŸÂ”Â','Ã°ÂŸÂ”Â  #love','Ã°ÂŸÂ”Â  #love  #instagood',\n",
    "             'Ã°ÂŸÂ˜','Ã°ÂŸÂ˜Â€','Ã°ÂŸÂ˜Â','Ã°ÂŸÂ˜Â‚','Ã°ÂŸÂ˜Â„',\n",
    "            'Ã°ÂŸÂ˜ÂŠ','Ã°ÂŸÂ˜Â','Ã°ÂŸÂ˜Â”','Ã°ÂŸÂ˜Â˜','Ã°ÂŸÂ˜Â™Ã°ÂŸÂ˜ÂŽÃ°ÂŸÂ‘Â„Ã°ÂŸÂ‘',\n",
    "            'Ã°ÂŸÂ˜Â™Ã°ÂŸÂ˜ÂŽÃ°ÂŸÂ‘Â„Ã°ÂŸÂ‘  Ã°ÂŸÂ’Â¦Ã°ÂŸÂ’Â¦Ã°ÂŸÂ’Â¦','Ã°ÂŸÂ˜Â¢',\n",
    "             'Ã¢Â€Â¦','!!','!!!','Ã¢Â€Â¦',        'Ã¢Â€Â¦','2','Ã°ÂŸÂ’Â¦Ã°ÂŸÂ’Â¦Ã°ÂŸÂ’Â¦',\n",
    "            'Ã°ÂŸÂ˜Â™Ã°ÂŸÂ˜ÂŽÃ°ÂŸÂ‘Â„Ã°ÂŸÂ‘  Ã°ÂŸÂ’Â¦Ã°ÂŸÂ’Â¦Ã°ÂŸÂ’Â¦','Ã°ÂŸÂ˜Â™Ã°ÂŸÂ˜ÂŽÃ°ÂŸÂ‘Â„Ã°ÂŸÂ‘',\n",
    "            '...','Ã¢Â†Â','4','1','3','Ã°ÂŸÂ˜ÂŠ','Ã¢ÂÂ¤Ã¯Â¸Â','.@user','#a','5',':(','Ã°ÂŸÂ˜Â','Ã¢Â€Â“',\n",
    "            '..','Ã°ÂŸÂ˜Â‚','Ã°ÂŸÂ˜Â”','10','Ã°ÂŸÂ˜Â','1st','7','Ã°ÂŸÂ˜Â¢','#Ã¢Â€Â¦','6','Ã°ÂŸÂ˜Â€','Ã°ÂŸÂ˜Â˜',\n",
    "              'Ã°ÂŸÂ’Â•','Ã°ÂŸÂ”Â','Ã¢ÂÂ¤','Ã°ÂŸÂ˜Â„','Ã°ÂŸÂ”Â  #love','50','2nd','8','Ã¢Â€Â”','Ã°ÂŸÂ˜','3d:',\n",
    "                'ð\\x9f\\x98\\x99ð\\x9f\\x98\\x8eð\\x9f\\x91\\x84ð\\x9f\\x91  ð\\x9f\\x92¦ð\\x9f\\x92¦ð\\x9f\\x92¦',\n",
    "              'Ã°ÂŸÂ˜Â™Ã°ÂŸÂ˜ÂŽÃ°ÂŸÂ‘Â„Ã°ÂŸÂ‘Â…Ã°ÂŸÂ’Â¦Ã°ÂŸÂ’Â¦Ã°ÂŸÂ’Â¦'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We need to analyse the text data stored in the 'tweet' column\n",
    "# Before that lets define some key functions\n",
    "# Creating functions to do tokenisation and punctuation removal\n",
    "\n",
    "# White space tokenizer\n",
    "def tokenize(text):\n",
    "    tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "    token = []\n",
    "    for item in text:\n",
    "        token.append(tokenizer.tokenize(item))\n",
    "        \n",
    "    # Removing stop words\n",
    "    ls_dummy1=[]\n",
    "    ls_dummy2=[]\n",
    "    temp=1\n",
    "    for i in token:\n",
    "        ls_dummy1=[]\n",
    "        for j in i:\n",
    "            if j in stop2:\n",
    "                temp=1\n",
    "            else:\n",
    "                ls_dummy1.append(j)\n",
    "        ls_dummy2.append(ls_dummy1)\n",
    "    l3=ls_dummy2\n",
    "        \n",
    "    return l3\n",
    "\n",
    "# Creating a function for removing the puntuation from text\n",
    "def rem_punctuation(data_frame,colname):\n",
    "    l3=[]\n",
    "    l2=[i for i in data_frame[colname]]\n",
    "    l3=tokenize(l2)\n",
    "\n",
    "    # Removing the punctuations\n",
    "    l5=[]\n",
    "    l6=[]\n",
    "    for j in l3:\n",
    "        for k in j:\n",
    "            if k in string.punctuation:\n",
    "                temp=1\n",
    "            else:\n",
    "                l5.append(k)\n",
    "        l6.append(l5)\n",
    "        l5=[]\n",
    "    c_ls=[\" \".join(i) for i in l6]\n",
    "    df1=pd.DataFrame(c_ls)\n",
    "    df1.columns=['Text']\n",
    "    return(df1)\n",
    "\n",
    "# We will now create a function that takes in text and ngram list\n",
    "# text/document is stores in a list\n",
    "# list also specifies ngram paramter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk import word_tokenize\n",
    "\n",
    "# The function should take the column containing text data\n",
    "def TF_NGRAM(data_frame,colname,ngram):\n",
    "    # Tokenize the data\n",
    "    DocID_ls=[]\n",
    "\n",
    "    #Appending the Doc_ID column\n",
    "    data_frame['Doc_ID']=[i for i in range(1,data_frame[colname].shape[0]+1)]\n",
    "\n",
    "\n",
    "    from nltk import ngrams       \n",
    "    l1=[]\n",
    "    for i in data_frame['Doc_ID']:\n",
    "        for k in data_frame[data_frame['Doc_ID']==i][colname]:\n",
    "            for j in ngram:\n",
    "                unigrams = ngrams(k.split(), j)\n",
    "                for z in unigrams:\n",
    "                    if j==1:\n",
    "                        l1.append(z[0])\n",
    "                    elif j==2:\n",
    "                        l1.append(z[0] + \" , \" +z[1])\n",
    "                    elif j==3:\n",
    "                        l1.append(z[0] + \" , \" +z[1]+\" , \" +z[2])\n",
    "                    elif j==4:\n",
    "                        l1.append(z[0] + \" , \" +z[1]+\" , \" +z[2] +\" , \" +z[3])\n",
    "\n",
    "                    DocID_ls.append(i)\n",
    "\n",
    "    # Creating a Data Frame out of it\n",
    "\n",
    "    s1=pd.Series(l1)\n",
    "    s2=pd.Series(DocID_ls)\n",
    "    df1=pd.DataFrame(s2)\n",
    "    df1['s1']=s1\n",
    "    df1.columns=['Doc_ID','Tokens']\n",
    "    df1\n",
    "    return(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is so selfish he drags his kids into his dysfunction.   #run</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't use cause they don't offer wheelchair vans in pdx.    #disapointed #getthanked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ur??!!! ??????????????????</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label  \\\n",
       "0  1   0       \n",
       "1  2   0       \n",
       "2  3   0       \n",
       "3  4   0       \n",
       "4  5   0       \n",
       "\n",
       "                                                                                                                        tweet  \n",
       "0   @user when a father is dysfunctional and is so selfish he drags his kids into his dysfunction.   #run                      \n",
       "1  @user @user thanks for #lyft credit i can't use cause they don't offer wheelchair vans in pdx.    #disapointed #getthanked  \n",
       "2    bihday your majesty                                                                                                       \n",
       "3  #model   i love u take with u all the time in ur??!!! ??????????????????                                                    \n",
       "4   factsguide: society now    #motivation                                                                                     "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If you look closely, there are certain characters such as Ã°ÂŸÂ’Â¦Ã°ÂŸÂ’Â¿Ã¢ÂœÂ (row 4 for instance)\n",
    "# These are meaningless and hence they need to be removed\n",
    "# Removing the special character/ascii character\n",
    "twt=[str(i).encode('ascii', 'ignore').decode(\"utf-8\") for i in df_train['tweet'] ]\n",
    "df_train['tweet']=twt\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31962, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing the special characters doesnt reduce the number of records \n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing punctuations, stop words etc\n",
    "df=rem_punctuation(df_train,'tweet')\n",
    "df.head()\n",
    "df.to_csv(\"cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Doc_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>father dysfunctional selfish drags kids dysfunction. #run</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>thanks #lyft credit can't use cause offer wheelchair vans pdx. #disapointed #getthanked</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>bihday majesty</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>#model love take time ur??!!! ??????????????????</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>factsguide: society #motivation</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                      Text  \\\n",
       "0  father dysfunctional selfish drags kids dysfunction. #run                                 \n",
       "1  thanks #lyft credit can't use cause offer wheelchair vans pdx. #disapointed #getthanked   \n",
       "2  bihday majesty                                                                            \n",
       "3  #model love take time ur??!!! ??????????????????                                          \n",
       "4  factsguide: society #motivation                                                           \n",
       "\n",
       "   Doc_ID  \n",
       "0  1       \n",
       "1  2       \n",
       "2  3       \n",
       "3  4       \n",
       "4  5       "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Doc_ID']=range(1,df.shape[0]+1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31962, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape\n",
    "# So no rows were removed during punctuation and stop word removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating the total number of blanks in df\n",
    "#len(np.where(df['Text'].applymap(lambda x: x == ''))[0]) # 19 ff them\n",
    "blnk_Doc_ID=df['Text']==\"\"\n",
    "df[blnk_Doc_ID].shape\n",
    "\n",
    "# There are 19 Doc_ID which are blank after Removing punctuations, stop words etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3982     3983 \n",
       "4411     4412 \n",
       "4799     4800 \n",
       "5235     5236 \n",
       "9034     9035 \n",
       "10802    10803\n",
       "13038    13039\n",
       "13287    13288\n",
       "13862    13863\n",
       "20261    20262\n",
       "28513    28514\n",
       "Name: Doc_ID, dtype: int32"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Storing the Doc_ID's that have blank in 'Text'\n",
    "ls_blnk_Doc_ID=df[blnk_Doc_ID]['Doc_ID']\n",
    "ls_blnk_Doc_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Doc_ID</th>\n",
       "      <th>Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>father</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>dysfunctional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>selfish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>drags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>kids</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>dysfunction.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>#run</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>father , dysfunctional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>dysfunctional , selfish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>selfish , drags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>drags , kids</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Doc_ID                   Tokens\n",
       "0   1       father                 \n",
       "1   1       dysfunctional          \n",
       "2   1       selfish                \n",
       "3   1       drags                  \n",
       "4   1       kids                   \n",
       "5   1       dysfunction.           \n",
       "6   1       #run                   \n",
       "7   1       father , dysfunctional \n",
       "8   1       dysfunctional , selfish\n",
       "9   1       selfish , drags        \n",
       "10  1       drags , kids           "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ngram frequency analysis\n",
    "# checking the ngram distribution\n",
    "ngram_df=TF_NGRAM(df,'Text',[1,2,3])\n",
    "ngram_df.head(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31951"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the number of unique 'Doc_ID' in ngram_df\n",
    "len(ngram_df['Doc_ID'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Doc_ID</th>\n",
       "      <th>Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>father</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>dysfunctional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>selfish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>drags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>kids</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Doc_ID         Tokens\n",
       "0  1       father       \n",
       "1  1       dysfunctional\n",
       "2  1       selfish      \n",
       "3  1       drags        \n",
       "4  1       kids         "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace all , in Tokens with \"\"\n",
    "import re\n",
    "ngram_df['Tokens']=ngram_df['Tokens'].apply(lambda x: re.sub(',','',x))\n",
    "ngram_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Doc_ID', 'Tokens'], dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(687224, 2)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31951"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the number of unique 'Doc_ID' in ngram_df\n",
    "len(ngram_df['Doc_ID'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we add the ones that had blanks in df (11 of them), then we would get 31951 which is the \n",
    "# total count of Doc_ID in the input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Doc_ID</th>\n",
       "      <th>Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>dummy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>dummy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>dummy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>dummy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>dummy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Doc_ID Tokens\n",
       "0  1       dummy\n",
       "1  2       dummy\n",
       "2  3       dummy\n",
       "3  4       dummy\n",
       "4  5       dummy"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a Data Frame that has 'dummy' values for all Doc_ID\n",
    "#ls_blnk_Doc_ID=list(blnk_Doc_ID)\n",
    "\n",
    "blnk_df=pd.DataFrame(df['Doc_ID'],columns=['Doc_ID'])\n",
    "blnk_df['Tokens']='dummy'\n",
    "blnk_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(687224, 2)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31962"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Binding ngram_df and blnk_df row wise\n",
    "ngram_df2=pd.concat([ngram_df,blnk_df],axis=0)\n",
    "len(ngram_df2['Doc_ID'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Doc_ID</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>#run</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>drags</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>drags  kids</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>drags  kids  dysfunction.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>dummy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Doc_ID                     Tokens  Frequency\n",
       "0  1       #run                       1        \n",
       "1  1       drags                      1        \n",
       "2  1       drags  kids                1        \n",
       "3  1       drags  kids  dysfunction.  1        \n",
       "4  1       dummy                      1        "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a summary at Doc_ID and Tokens level\n",
    "ngram_df2['Frequency']=1\n",
    "ngram_df0=ngram_df2.groupby(['Doc_ID','Tokens'])['Frequency'].sum().reset_index()\n",
    "ngram_df0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>dummy</td>\n",
       "      <td>31962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>???</td>\n",
       "      <td>1521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>day</td>\n",
       "      <td>1452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>#love</td>\n",
       "      <td>1449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>happy</td>\n",
       "      <td>1294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  Count\n",
       "0  dummy  31962\n",
       "1  ???    1521 \n",
       "2  day    1452 \n",
       "3  #love  1449 \n",
       "4  happy  1294 "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the summary at an overall level\n",
    "freq_dist=nltk.FreqDist(ngram_df0['Tokens'])\n",
    "df5=pd.DataFrame(pd.Series(freq_dist),columns=['Count'])\n",
    "df5.sort_values(['Count'])\n",
    "df6=df5.sort_values(['Count'],ascending=False).reset_index()\n",
    "df6.shape # 827k records\n",
    "df6.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(876, 2)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Filtering out the ngrams\n",
    "df7=df6[df6['Count'] > 50]\n",
    "df7.shape\n",
    "# For the first run lets keep features identified in df7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Writing the tokens to a file\n",
    "df7.to_csv(\"tokens.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "876"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "token=[i for i in df7['index']]\n",
    "len(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Doc_ID</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>dummy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>father</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>kids</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>can't</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>cause</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Doc_ID  Tokens  Frequency\n",
       "4   1       dummy   1        \n",
       "10  1       father  1        \n",
       "13  1       kids    1        \n",
       "25  2       can't   1        \n",
       "28  2       cause   1        "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the DTM\n",
    "pos=[i in token for i in ngram_df0['Tokens']] # filtering on the tokens given in 'token' list\n",
    "ngram_df_DTM0=ngram_df0[pos]\n",
    "ngram_df_DTM0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(154805, 3)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram_df_DTM0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Tokens</th>\n",
       "      <th>Doc_ID</th>\n",
       "      <th>#2016</th>\n",
       "      <th>#?</th>\n",
       "      <th>#??</th>\n",
       "      <th>#affirmation</th>\n",
       "      <th>#affirmations</th>\n",
       "      <th>#allahsoil</th>\n",
       "      <th>#altwaystoheal</th>\n",
       "      <th>#altwaystoheal  #healthy</th>\n",
       "      <th>#amazing</th>\n",
       "      <th>...</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>yes</th>\n",
       "      <th>yet</th>\n",
       "      <th>yo</th>\n",
       "      <th>you</th>\n",
       "      <th>you!</th>\n",
       "      <th>you.</th>\n",
       "      <th>you?</th>\n",
       "      <th>young</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 877 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Tokens  Doc_ID  #2016   #?  #??  #affirmation  #affirmations  #allahsoil  \\\n",
       "0       1       0.0    0.0  0.0  0.0           0.0            0.0          \n",
       "1       2       0.0    0.0  0.0  0.0           0.0            0.0          \n",
       "2       3       0.0    0.0  0.0  0.0           0.0            0.0          \n",
       "3       4       0.0    0.0  0.0  0.0           0.0            0.0          \n",
       "4       5       0.0    0.0  0.0  0.0           0.0            0.0          \n",
       "\n",
       "Tokens  #altwaystoheal  #altwaystoheal  #healthy  #amazing  ...  year  years  \\\n",
       "0       0.0             0.0                       0.0       ...  0.0   0.0     \n",
       "1       0.0             0.0                       0.0       ...  0.0   0.0     \n",
       "2       0.0             0.0                       0.0       ...  0.0   0.0     \n",
       "3       0.0             0.0                       0.0       ...  0.0   0.0     \n",
       "4       0.0             0.0                       0.0       ...  0.0   0.0     \n",
       "\n",
       "Tokens  yes  yet   yo  you  you!  you.  you?  young  \n",
       "0       0.0  0.0  0.0  0.0  0.0   0.0   0.0   0.0    \n",
       "1       0.0  0.0  0.0  0.0  0.0   0.0   0.0   0.0    \n",
       "2       0.0  0.0  0.0  0.0  0.0   0.0   0.0   0.0    \n",
       "3       0.0  0.0  0.0  0.0  0.0   0.0   0.0   0.0    \n",
       "4       0.0  0.0  0.0  0.0  0.0   0.0   0.0   0.0    \n",
       "\n",
       "[5 rows x 877 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pivotting df3 \n",
    "ngram_df_DTM=ngram_df_DTM0.pivot(index='Doc_ID',columns='Tokens',values='Frequency').fillna(0).reset_index()\n",
    "ngram_df_DTM.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31962, 877)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram_df_DTM.shape\n",
    "# ngram_df_DTM has all the Doc_IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing the columns to a csv\n",
    "clm=ngram_df_DTM.columns\n",
    "np.array([clm])\n",
    "#pd.DataFrame(np.array([clm]).to_csv(\"C:\\\\NLP in Python\\\\Sentiment Analysis Analytics Vidya\\\\final_features.csv\")\n",
    "ngram_df_DTM.to_csv(\"ngram_DTM.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31962, 877)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dimension of ngram_df_DTM\n",
    "ngram_df_DTM.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31962, 880)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Joining this with the 'id' column from input data frame(df_train) to bring in the labels \n",
    "\n",
    "# LEFT JOIN\n",
    "df_final=pd.merge(ngram_df_DTM,df_train,left_on='Doc_ID',right_on='id',how='left')\n",
    "df_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Doc_ID</th>\n",
       "      <th>#2016</th>\n",
       "      <th>#?</th>\n",
       "      <th>#??</th>\n",
       "      <th>#affirmation</th>\n",
       "      <th>#affirmations</th>\n",
       "      <th>#allahsoil</th>\n",
       "      <th>#altwaystoheal</th>\n",
       "      <th>#altwaystoheal  #healthy</th>\n",
       "      <th>#amazing</th>\n",
       "      <th>...</th>\n",
       "      <th>yet</th>\n",
       "      <th>yo</th>\n",
       "      <th>you</th>\n",
       "      <th>you!</th>\n",
       "      <th>you.</th>\n",
       "      <th>you?</th>\n",
       "      <th>young</th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is so selfish he drags his kids into his dysfunction.   #run</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't use cause they don't offer wheelchair vans in pdx.    #disapointed #getthanked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ur??!!! ??????????????????</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 880 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Doc_ID  #2016   #?  #??  #affirmation  #affirmations  #allahsoil  \\\n",
       "0  1       0.0    0.0  0.0  0.0           0.0            0.0          \n",
       "1  2       0.0    0.0  0.0  0.0           0.0            0.0          \n",
       "2  3       0.0    0.0  0.0  0.0           0.0            0.0          \n",
       "3  4       0.0    0.0  0.0  0.0           0.0            0.0          \n",
       "4  5       0.0    0.0  0.0  0.0           0.0            0.0          \n",
       "\n",
       "   #altwaystoheal  #altwaystoheal  #healthy  #amazing  ...  yet   yo  you  \\\n",
       "0  0.0             0.0                       0.0       ...  0.0  0.0  0.0   \n",
       "1  0.0             0.0                       0.0       ...  0.0  0.0  0.0   \n",
       "2  0.0             0.0                       0.0       ...  0.0  0.0  0.0   \n",
       "3  0.0             0.0                       0.0       ...  0.0  0.0  0.0   \n",
       "4  0.0             0.0                       0.0       ...  0.0  0.0  0.0   \n",
       "\n",
       "   you!  you.  you?  young  id  label  \\\n",
       "0  0.0   0.0   0.0   0.0    1   0       \n",
       "1  0.0   0.0   0.0   0.0    2   0       \n",
       "2  0.0   0.0   0.0   0.0    3   0       \n",
       "3  0.0   0.0   0.0   0.0    4   0       \n",
       "4  0.0   0.0   0.0   0.0    5   0       \n",
       "\n",
       "                                                                                                                      tweet_y  \n",
       "0   @user when a father is dysfunctional and is so selfish he drags his kids into his dysfunction.   #run                      \n",
       "1  @user @user thanks for #lyft credit i can't use cause they don't offer wheelchair vans in pdx.    #disapointed #getthanked  \n",
       "2    bihday your majesty                                                                                                       \n",
       "3  #model   i love u take with u all the time in ur??!!! ??????????????????                                                    \n",
       "4   factsguide: society now    #motivation                                                                                     \n",
       "\n",
       "[5 rows x 880 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "nm=pd.DataFrame(df_final.columns,columns=['Col_Name'])\n",
    "nm.to_csv(\"Final_Features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    29720\n",
       "1    2242 \n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking the number of ones in label column\n",
    "df_final['label'].value_counts()\n",
    "\n",
    "# in the input train data, following is the 0 and 1 distribution\n",
    "# 29720 '0'\n",
    "# 2242 '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries for building the model\n",
    "# mostly it will be the functions around sklearn library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "plt.rc(\"font\", size=14)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# Feature Selection\n",
    "from sklearn import datasets\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(style=\"white\")\n",
    "sns.set(style=\"whitegrid\", color_codes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "875"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Independent variable list\n",
    "df_final.columns\n",
    "\n",
    "# Removing 'dummy' column from the list\n",
    "df_final2=df_final.drop(['Doc_ID','dummy','id','label','tweet_y'],axis=1)\n",
    "\n",
    "# Storing the IV list in X\n",
    "X=list(df_final2.columns)\n",
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets run the Model\n",
    "# Splitting the data into test and train\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train=df_final[X]\n",
    "y_train = df_final['label']\n",
    "\n",
    "\n",
    "# Importing Logistic regression model from sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Making an instance of the model\n",
    "LogisticRegr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\Desktop\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 5.56767241e-01,  7.76077977e-01, -7.29563365e-01,\n",
       "        -7.48812887e-01, -4.85069848e-01,  5.16191993e+00,\n",
       "        -8.82608389e-01, -5.92450973e-01, -9.49921350e-01,\n",
       "        -5.68436062e-01, -8.07497218e-01, -7.66334388e-01,\n",
       "        -6.84346060e-01, -1.29328008e+00, -1.37226791e-02,\n",
       "        -5.23554411e-01, -1.79752235e+00,  1.41474250e+00,\n",
       "        -1.42632958e+00, -1.03905474e+00, -5.85968502e-01,\n",
       "        -3.48046092e-01, -8.45208541e-01, -1.35336602e+00,\n",
       "        -5.46155381e-01, -6.95296181e-01, -7.97662851e-02,\n",
       "        -7.97662851e-02, -1.50552643e+00, -4.57048046e-03,\n",
       "        -4.51503871e-03, -4.27156124e-01, -8.09488793e-01,\n",
       "        -1.49524303e+00, -1.07401578e-01, -1.03225983e+00,\n",
       "        -9.72591874e-01, -7.90779532e-02, -7.90779532e-02,\n",
       "        -7.90779532e-02, -1.12290530e+00, -7.93394750e-01,\n",
       "        -1.69472246e+00, -1.55860465e+00, -1.06342004e+00,\n",
       "        -5.57227051e-01, -6.45423050e-01, -5.94323823e-01,\n",
       "        -1.58579808e+00, -1.00327097e+00, -1.09168677e+00,\n",
       "        -8.17977068e-01, -6.15408135e-02, -4.75317725e-01,\n",
       "        -3.19725892e-01, -6.87906684e-01, -1.60662620e+00,\n",
       "        -6.94186387e-01, -1.21738367e-01, -1.52109624e+00,\n",
       "        -1.64326857e+00, -1.12948564e+00, -2.89466335e-01,\n",
       "        -1.21666676e+00, -7.30674957e-01, -7.15537130e-01,\n",
       "        -2.86870083e-01, -6.27818479e-01, -8.12037405e-01,\n",
       "        -1.31688992e+00, -3.33090371e-01, -4.87510041e-01,\n",
       "        -7.04618289e-01, -1.56909281e+00, -9.00287274e-01,\n",
       "         2.33368269e+00, -6.19670328e-01, -8.99137057e-01,\n",
       "        -2.05567962e+00, -7.94235275e-01, -3.97058930e-01,\n",
       "        -7.97662851e-02, -4.14345214e-01, -8.72590845e-01,\n",
       "        -4.21064725e-01, -4.21064725e-01, -4.21064725e-01,\n",
       "        -1.06888937e+00, -1.07496702e+00, -2.17735017e-02,\n",
       "        -3.55081897e-03, -8.24080888e-01, -7.29447548e-01,\n",
       "        -2.18236402e-01,  4.91687022e-01,  7.94368593e-01,\n",
       "         1.39756389e-01,  1.95598838e+00,  1.39756389e-01,\n",
       "         1.39756389e-01, -1.50816358e+00, -4.94685888e-01,\n",
       "        -1.67724333e-01, -7.90779532e-02, -8.68036396e-01,\n",
       "        -2.52101035e-01, -8.79869695e-01, -1.42828314e+00,\n",
       "        -1.77736759e-02, -1.31002905e-02, -6.93320070e-01,\n",
       "        -4.52457234e-01, -2.77030099e-02, -5.21559513e-03,\n",
       "        -3.69801011e-01, -4.99069785e-01, -1.86542747e-01,\n",
       "        -1.86542747e-01, -8.04854465e-01, -5.22823854e-01,\n",
       "        -1.71525185e+00, -1.32693655e+00, -1.02955828e+00,\n",
       "        -2.85705137e-01, -9.59665416e-01,  8.95438164e-01,\n",
       "        -5.91149882e-01, -2.22818650e+00, -1.04698886e+00,\n",
       "        -8.21067503e-01,  1.10176589e+00, -4.39192339e-02,\n",
       "        -7.85976788e-01, -1.08018113e+00, -5.19160703e-01,\n",
       "        -3.55081897e-03, -3.55081897e-03, -5.69525850e-01,\n",
       "         2.39939586e+00, -4.09077472e-01, -1.91131815e+00,\n",
       "        -6.58036704e-01, -1.53724955e+00, -1.35943155e+00,\n",
       "        -1.16617435e+00, -9.57241379e-01, -7.93862492e-01,\n",
       "         1.02214036e+00, -8.49539097e-01, -3.85584521e-01,\n",
       "        -1.11705196e+00, -6.47971485e-01, -6.76452566e-02,\n",
       "        -5.32728773e-01, -7.97662851e-02, -7.97662851e-02,\n",
       "        -7.94327629e-01, -3.48046092e-01, -2.86870083e-01,\n",
       "         1.31625657e+00,  1.39756389e-01,  1.39756389e-01,\n",
       "        -4.26509371e-01, -1.94726826e+00, -8.14566497e-01,\n",
       "        -1.01691942e+00, -1.76186237e+00, -7.92383113e-01,\n",
       "        -1.12995457e+00, -5.98531009e-01, -7.64652422e-01,\n",
       "        -2.26986296e-02, -3.97299567e-03, -1.19987057e+00,\n",
       "        -1.13561644e+00, -5.57126247e-01, -8.87645463e-01,\n",
       "        -9.23983624e-01, -7.76047840e-01, -1.30186245e+00,\n",
       "         2.92529468e+00,  1.07393395e-01,  9.80904923e-01,\n",
       "        -9.18272967e-01, -1.29844778e+00, -1.18801728e+00,\n",
       "        -1.12170482e-01, -5.22903025e-01, -8.84552003e-01,\n",
       "        -5.80360533e-01, -1.84843812e-01,  1.11701185e+00,\n",
       "        -1.49982875e+00, -9.56132608e-01, -6.48919759e-01,\n",
       "        -5.09245556e-02, -2.71690810e-03, -8.94230295e-01,\n",
       "        -6.27222230e-01, -1.45531062e+00, -1.44132868e+00,\n",
       "        -1.44989866e+00, -1.46235050e+00, -8.86330126e-01,\n",
       "        -1.17369926e+00, -9.67756271e-01, -1.49892367e+00,\n",
       "        -1.06372533e+00, -1.13503060e+00, -5.79188143e-01,\n",
       "         2.08639123e+00, -6.35509517e-01, -2.60748586e-01,\n",
       "        -2.60748586e-01, -2.60748586e-01, -4.92099441e-01,\n",
       "        -4.76921141e-01,  6.60465406e-01, -6.69300774e-01,\n",
       "        -1.55570654e+00,  7.98009348e-01, -8.52299892e-01,\n",
       "        -1.74684530e-02, -1.74684530e-02, -5.76355761e-01,\n",
       "         1.65791802e-01, -3.21535399e-01, -6.71850320e-01,\n",
       "        -1.17292862e-01,  6.91817360e-01, -5.56915061e-01,\n",
       "        -1.17292862e-01, -7.86134304e-01, -8.38175200e-01,\n",
       "        -5.52540119e-01, -1.71299059e-01, -1.71299059e-01,\n",
       "         3.05697381e-01, -8.53778448e-01,  9.81930486e-02,\n",
       "        -9.86894428e-01, -4.02183613e-01, -5.88966181e-01,\n",
       "        -3.49369060e-02, -1.74684530e-02, -1.74684530e-02,\n",
       "        -1.74684530e-02, -1.74684530e-02, -1.35190727e+00,\n",
       "        -1.16198301e-01, -6.56824043e-01, -7.92370874e-02,\n",
       "        -9.85005744e-01,  9.15041164e-02, -3.04389589e-01,\n",
       "        -2.54370241e+00, -3.56800435e-01, -3.42598119e-01,\n",
       "        -1.71299059e-01, -1.15175621e+00,  7.80233079e-01,\n",
       "         1.53072584e+00, -5.60587462e-01, -3.42598119e-01,\n",
       "        -1.71299059e-01, -1.71299059e-01,  3.66457245e-01,\n",
       "        -8.63694922e-01, -5.50005088e-01, -9.23461867e-02,\n",
       "        -9.67252458e-01,  1.06262629e+00, -2.88425642e-01,\n",
       "        -2.88425642e-01, -2.88425642e-01, -2.88425642e-01,\n",
       "        -1.02849531e+00, -6.75423772e-02, -6.75423772e-02,\n",
       "        -1.17292862e-01, -1.17292862e-01, -1.67058745e-01,\n",
       "        -1.67058745e-01, -6.75423772e-02, -6.75423772e-02,\n",
       "         9.63430585e-01,  1.96962441e-02,  1.48313552e+00,\n",
       "         5.75267577e-01, -6.49178115e-03, -2.20452719e-01,\n",
       "        -7.75131178e-02, -7.30205225e-01, -5.31630673e-01,\n",
       "        -2.25346615e-01, -5.51208282e-01, -6.05524354e-01,\n",
       "        -7.23538099e-01, -1.22784127e-01, -7.27477601e-01,\n",
       "         4.88425293e-01, -6.02482297e-02, -4.32505050e-01,\n",
       "         1.36268754e-01, -6.00919828e-01, -1.74684530e-02,\n",
       "        -1.74684530e-02, -1.74684530e-02, -1.74684530e-02,\n",
       "        -1.67058745e-01, -1.67058745e-01, -1.67058745e-01,\n",
       "         3.44592637e-01, -4.77183603e-01, -1.53867329e-02,\n",
       "        -4.05202089e-01,  1.34455989e-02, -7.52804874e-01,\n",
       "        -1.84057160e-01, -1.67058745e-01, -1.67058745e-01,\n",
       "        -1.51404313e-01, -6.20049938e-01, -3.75914575e-01,\n",
       "         4.76313184e-01, -4.65549359e-01,  1.37097235e-01,\n",
       "        -1.20627924e-01, -1.20627924e-01, -1.12170482e-01,\n",
       "        -1.25351298e+00, -3.45494176e-01, -6.10352179e-01,\n",
       "         1.50733015e-01, -4.56754433e-01, -9.23506019e-01,\n",
       "        -1.99017977e+00, -1.24837662e+00, -1.24521470e+00,\n",
       "        -1.84643911e+00, -4.44701610e-01,  6.48510966e-01,\n",
       "         3.11069233e-01,  1.26084586e+00, -1.09173408e-01,\n",
       "        -1.09173408e-01,  3.48919430e-01, -3.34173177e-01,\n",
       "        -6.75423772e-02, -6.75423772e-02, -8.03073746e-01,\n",
       "        -1.16001339e+00, -6.75423772e-02, -6.75423772e-02,\n",
       "        -6.75423772e-02, -4.17592231e-04, -5.34345170e-02,\n",
       "        -9.37125566e-01, -2.83258221e-02, -1.06930179e+00,\n",
       "        -1.06877753e+00, -9.08500312e-01, -1.17292862e-01,\n",
       "        -1.17292862e-01,  4.81498110e-01, -9.68278043e-01,\n",
       "        -1.10825524e+00,  1.00080730e+00, -3.83491184e-01,\n",
       "        -2.60748586e-01, -2.60748586e-01, -4.17612299e-01,\n",
       "        -2.39539175e-01,  3.65708717e-01,  2.20502806e-02,\n",
       "        -4.69856221e-02, -7.31719745e-03, -1.90688838e+00,\n",
       "         6.21256665e-01, -1.02502486e+00, -6.79815080e-01,\n",
       "        -6.03891562e-03,  8.09218553e-02, -3.73522692e-01,\n",
       "        -1.44415688e+00, -3.18529257e-01, -6.31458596e-01,\n",
       "        -3.45803252e-01, -5.46125495e-01, -8.15978968e-01,\n",
       "        -5.53024395e-01,  5.92645214e-01, -1.37855270e+00,\n",
       "        -9.73808155e-01, -1.25094031e+00, -1.09748953e-01,\n",
       "        -1.09173408e-01, -1.57504973e-01, -1.09173408e-01,\n",
       "        -1.09173408e-01, -8.91239257e-01, -1.06586106e+00,\n",
       "        -6.32809578e-01, -7.55202040e-01, -1.04544345e+00,\n",
       "         3.47798615e-01, -8.69000967e-01, -5.26418403e-01,\n",
       "        -1.09173408e-01, -1.09173408e-01, -2.40869943e-01,\n",
       "        -1.51536630e+00, -5.13278747e-01, -6.53894146e-01,\n",
       "         1.31378121e+00,  3.32838322e-01, -7.32244795e-01,\n",
       "        -3.37750533e-01, -1.90391056e-01,  4.05448470e-02,\n",
       "        -1.17292862e-01, -1.17292862e-01, -1.83740112e-01,\n",
       "        -7.97662851e-02, -5.20426631e-01, -1.09243973e-01,\n",
       "        -7.97662851e-02,  1.11847848e+00, -1.53996362e+00,\n",
       "        -7.24128144e-01,  3.63636255e-01,  6.85661748e-01,\n",
       "         2.98233975e-01, -1.55374373e-01, -6.11729233e-01,\n",
       "        -2.41910972e-01, -5.35483558e-01, -2.96109263e-01,\n",
       "        -5.47026494e-01,  9.39068469e-02, -1.71299059e-01,\n",
       "        -1.71299059e-01, -4.00856438e-01,  1.89106596e-01,\n",
       "        -2.60748586e-01, -2.60748586e-01, -5.45771482e-01,\n",
       "        -5.10956710e-01,  3.33323090e-02, -4.09113224e-01,\n",
       "        -1.71141067e+00,  5.64089746e-01, -6.00256277e-01,\n",
       "         1.24830660e-01, -2.63439757e-01, -1.25073143e+00,\n",
       "        -1.54420357e+00, -6.70041880e-02, -4.58406643e-02,\n",
       "        -1.04210826e-02, -8.71049139e-01, -2.68609781e-01,\n",
       "        -2.10106156e+00,  5.56414630e-01,  1.62132282e-01,\n",
       "        -1.32173697e+00, -2.89278919e-01, -1.17292862e-01,\n",
       "        -1.17292862e-01, -4.04825940e-01, -1.51910912e-01,\n",
       "        -1.00070733e-01,  9.40231189e-02,  1.61367563e-01,\n",
       "        -7.97662851e-02, -7.97662851e-02, -9.23308480e-02,\n",
       "        -1.30225264e+00, -4.54822885e-01, -1.67058745e-01,\n",
       "        -1.67058745e-01, -7.57248843e-01,  4.59951765e-01,\n",
       "        -7.19362953e-01, -2.64602128e-01, -2.88425642e-01,\n",
       "        -3.57879926e-02, -1.21427187e+00, -5.30068293e-01,\n",
       "        -1.25757989e+00,  4.96330881e-01,  3.95718173e-01,\n",
       "        -8.91338568e-01, -3.49605346e-01, -3.33090371e-01,\n",
       "        -3.33090371e-01, -2.32340718e-03,  1.39756389e-01,\n",
       "         1.39756389e-01,  1.39756389e-01, -1.86093279e-01,\n",
       "         4.61988136e-01, -4.36615231e-01,  1.03412885e-02,\n",
       "         6.04152804e-01, -5.05528910e-01, -1.35765232e+00,\n",
       "         4.25816607e-01, -2.09939304e-01, -7.42011193e-02,\n",
       "        -1.56411743e+00,  3.81848404e-01, -7.39027685e-01,\n",
       "        -8.88952454e-01, -7.05600997e-01,  2.15913667e+00,\n",
       "         4.73606753e-01, -1.20627924e-01, -1.20627924e-01,\n",
       "        -1.66668966e-01,  2.70211397e-01, -3.34567420e-01,\n",
       "         4.80383979e-01,  5.22141705e-01, -2.82451406e-01,\n",
       "         2.93645256e-02,  1.39756389e-01,  1.39756389e-01,\n",
       "        -1.44492126e+00, -1.06661797e+00,  9.14687650e-02,\n",
       "         4.58647878e-01,  2.28238722e+00, -1.01832846e+00,\n",
       "        -9.11288409e-02,  3.65629069e-01, -3.87736500e-01,\n",
       "        -1.74684530e-02, -1.53867329e-02, -6.59431161e-01,\n",
       "        -5.29777071e-01,  3.00754798e-01, -9.29315061e-01,\n",
       "        -6.50364916e-01, -5.79417577e-01,  5.34726314e-01,\n",
       "        -1.43563533e-01, -3.27275385e-01, -1.19697465e+00,\n",
       "        -1.86542747e-01, -1.86542747e-01, -1.15981618e+00,\n",
       "        -4.43129754e-01, -9.83761150e-02, -1.48463536e-01,\n",
       "        -5.08648492e-01, -2.79593651e-01, -7.88584677e-01,\n",
       "         3.27753418e-01,  3.42840033e-02,  9.13826379e-01,\n",
       "        -2.69757529e-01,  4.63740408e-01, -3.81355094e-01,\n",
       "         6.68231618e-01,  3.55073999e-02, -4.41583104e-01,\n",
       "        -1.02890307e+00,  1.37176494e+00,  7.43361374e-02,\n",
       "        -1.09173408e-01, -1.09173408e-01,  1.39756389e-01,\n",
       "         1.39756389e-01, -4.77804222e-01, -4.54828286e-01,\n",
       "        -1.07321580e-01, -1.07321580e-01, -5.09220247e-01,\n",
       "        -4.77812109e-01, -1.99135578e+00, -1.30608751e+00,\n",
       "        -1.10556560e+00, -6.69399973e-01, -1.31307374e+00,\n",
       "        -5.59945072e-01, -1.89378587e+00, -3.55910550e-01,\n",
       "        -7.80881561e-01, -2.18588669e-01, -3.32840137e-01,\n",
       "         1.35431510e-01, -9.61318542e-02, -5.32252653e-01,\n",
       "         1.92301590e-01, -2.60748586e-01, -2.60748586e-01,\n",
       "        -2.60748586e-01, -2.42981385e-01,  1.31643358e-01,\n",
       "         2.25893339e-02,  4.66915075e-02,  1.42910384e-01,\n",
       "        -3.59594527e-01,  3.34291267e-01, -7.93411070e-01,\n",
       "        -1.53025739e+00,  2.13261836e-01, -3.98743107e-01,\n",
       "         1.71770474e+00, -2.78508309e-01, -3.91994531e-01,\n",
       "        -8.61881278e-01, -1.09173408e-01, -1.09173408e-01,\n",
       "        -6.33813684e-01, -1.03058538e-01, -2.98688617e-01,\n",
       "        -8.50747621e-01, -2.85291420e-01, -1.12170482e-01,\n",
       "        -1.12170482e-01, -1.40337892e+00, -2.26538875e-01,\n",
       "         4.37053960e-01,  4.63962388e-01, -6.47596822e-01,\n",
       "        -1.16169837e-01, -4.84966424e-01,  4.61462996e-01,\n",
       "        -3.23967380e-01, -9.97628385e-01, -5.33270793e-02,\n",
       "        -2.09137769e-01, -1.15969405e+00,  2.97999985e-01,\n",
       "        -1.94719583e-01, -1.87065768e-01, -1.13648685e-01,\n",
       "        -3.49369060e-02, -1.74684530e-02,  1.01282269e+00,\n",
       "         8.71472534e-02,  3.09868376e-01, -4.73632202e-02,\n",
       "        -9.60382513e-01, -2.07362075e-01,  3.51880653e-01,\n",
       "        -3.72120609e-01,  9.17390273e-02,  2.23192544e+00,\n",
       "        -1.15809087e-01, -1.74684530e-02, -1.74684530e-02,\n",
       "        -1.74684530e-02, -1.74684530e-02, -1.74684530e-02,\n",
       "         2.34357456e+00, -4.71462564e-01, -1.67058745e-01,\n",
       "        -1.67058745e-01, -9.19621753e-01,  2.61007086e-01,\n",
       "         4.85984504e-01, -1.90406779e+00,  3.61247886e-01,\n",
       "        -4.19992344e-01,  9.11634776e-01, -1.17292862e-01,\n",
       "         1.69820768e-02, -2.36499649e-01, -6.71414757e-02,\n",
       "        -3.13950795e-01, -9.24504478e-01,  2.90014991e-01,\n",
       "         3.44523988e-01, -1.20430743e+00,  4.12711630e-01,\n",
       "        -7.85673027e-01,  3.12838157e-01,  1.04207564e+00,\n",
       "         1.16477457e+00,  4.79968995e-01, -1.41890084e+00,\n",
       "        -4.99422345e-01, -9.80802196e-01,  4.58778012e-01,\n",
       "        -4.41022021e-01,  2.43645718e-01, -9.92420335e-01,\n",
       "        -4.17162343e-05, -5.34850386e-02, -1.13989607e-01,\n",
       "        -8.96716877e-01,  3.19970635e-01, -1.19222837e+00,\n",
       "        -6.42315129e-01, -2.88425642e-01, -2.88425642e-01,\n",
       "        -2.60748586e-01, -2.60748586e-01, -2.60748586e-01,\n",
       "        -6.93429222e-01,  4.66342791e-02, -7.94037214e-01,\n",
       "        -1.46484584e+00, -1.49115268e-01, -8.80019694e-01,\n",
       "        -1.20629964e+00, -8.11336079e-01, -8.72709127e-01,\n",
       "        -3.48756093e-01,  2.70186445e-01, -8.76329841e-01,\n",
       "        -7.38995756e-01, -9.83304742e-01, -3.69677588e-01,\n",
       "        -3.79045587e-01, -2.02094675e-01,  8.09878111e-01,\n",
       "        -4.55948716e-01, -7.61969119e-01, -1.19636866e+00,\n",
       "        -9.13506090e-01, -1.05710595e+00, -4.38145436e-01,\n",
       "        -1.01989129e-01, -5.69879382e-01, -1.67058745e-01,\n",
       "         5.09982030e-02, -3.38226007e-01, -1.86542747e-01,\n",
       "        -2.88425642e-01, -2.88425642e-01, -5.76685191e-03,\n",
       "        -1.07336515e+00, -2.84603017e-01,  5.44028024e-01,\n",
       "         1.63358505e+00, -1.67058745e-01, -1.67058745e-01,\n",
       "        -1.75345922e-01, -1.67058745e-01,  4.45619866e-01,\n",
       "        -5.38612119e-01, -2.42981385e-01,  1.33699549e-01,\n",
       "        -4.71947909e-01, -9.58261722e-01,  5.76717197e-03,\n",
       "         1.41622919e-01, -1.88916301e-01,  7.36164238e-02,\n",
       "         2.69982734e-01, -1.32999379e+00,  2.29202789e-01,\n",
       "        -1.17292862e-01, -1.17292862e-01,  8.44766379e-01,\n",
       "        -5.31678607e-01, -3.19774121e-01, -1.23287273e+00,\n",
       "        -3.16466407e-01, -6.80178483e-01, -1.86542747e-01,\n",
       "        -1.86542747e-01,  3.49999767e-02,  8.57498922e-02,\n",
       "        -1.40276446e+00, -2.05239466e+00, -7.03202692e-01,\n",
       "        -1.35120962e+00,  4.72635731e-01, -1.79386301e+00,\n",
       "        -9.06250087e-01, -1.21780117e+00, -8.21446005e-02,\n",
       "        -3.55081897e-03, -3.11956748e-03, -1.06280177e+00,\n",
       "         1.09998724e-01,  2.24875947e-01,  8.93394112e-01,\n",
       "        -5.56448996e-01,  1.83335776e-01, -6.39526397e-01,\n",
       "         2.66298404e-01, -1.21116171e-01, -1.09173408e-01,\n",
       "        -1.09173408e-01, -1.42875955e-01, -9.34312179e-01,\n",
       "        -4.66789992e-01, -6.75423772e-02, -6.75423772e-02,\n",
       "        -6.75423772e-02, -1.18849549e+00, -4.01433223e-01,\n",
       "        -1.86542747e-01, -1.86542747e-01,  2.53888811e-01,\n",
       "         4.98414555e-01, -2.93342835e-01, -2.61498062e-01,\n",
       "        -1.09173408e-01, -1.07401578e-01, -2.63379887e-01,\n",
       "         7.10972878e-01, -2.88425642e-01, -2.88425642e-01,\n",
       "        -2.88425642e-01, -3.74179981e-01,  8.74829425e-01,\n",
       "        -1.08751818e+00,  2.40184105e-01, -4.23866426e-01,\n",
       "         6.59387228e-02, -1.37997207e+00, -3.56810110e-01,\n",
       "        -4.66863341e-01,  1.11559990e-01, -4.15442745e-01,\n",
       "        -9.28725823e-02, -1.25081321e-01,  2.53071955e-01,\n",
       "        -7.17186476e-01, -1.21666426e+00, -5.27371556e-01,\n",
       "        -1.09173408e-01, -1.09173408e-01,  7.65032195e-01,\n",
       "        -7.60056714e-01, -1.21815431e+00, -1.60393925e+00,\n",
       "        -7.26883314e-01,  9.44366955e-02, -4.49378251e-01,\n",
       "        -1.09173408e-01, -1.07401578e-01, -6.31776878e-01,\n",
       "        -5.50398763e-01, -1.15233262e+00, -6.75423772e-02,\n",
       "        -6.75423772e-02,  2.72551059e+00, -2.29620613e-01,\n",
       "         3.44225897e-01,  3.34959354e-02, -7.55108075e-01,\n",
       "         3.69069689e-02,  1.69382306e+00,  1.72423540e+00,\n",
       "        -3.51563147e-01,  1.20272465e+00,  2.20953381e-01,\n",
       "        -4.44371976e-01, -3.13683301e-01, -6.78365404e-01,\n",
       "         5.50035914e-01, -2.42993493e-01, -4.40413272e-02,\n",
       "        -8.35925206e-01, -8.11759126e-03, -1.71299059e-01,\n",
       "        -1.71299059e-01,  3.48752553e-01,  1.18956619e-01,\n",
       "        -6.02344019e-01, -3.31432218e-01, -1.64813862e-01,\n",
       "        -3.13363600e-01, -1.07320976e+00, -7.74137389e-01,\n",
       "         7.33392093e-01, -5.49078693e-01]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "LogisticRegr.fit(x_train, y_train)\n",
    "LogisticRegr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the train data set\n",
    "prediction_reg=LogisticRegr.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.94574807584006\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Lets measure the score\n",
    "score = LogisticRegr.score(x_train, y_train)\n",
    "print(score)\n",
    "\n",
    "# score is nothing but the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[29574   146]\n",
      " [ 1588   654]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "\n",
    "y_train.shape\n",
    "prediction_reg.shape\n",
    "\n",
    "cm = metrics.confusion_matrix(y_train, prediction_reg)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94574807584006"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy\n",
    "acc=(cm[0][0] + cm[1][1])/(cm[0][0]+cm[0][1]+cm[1][0]+cm[1][1])\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.29170383586083853"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Senstivity\n",
    "sens=cm[1][1]/(cm[1][1]+cm[1][0])\n",
    "sens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9950874831763122"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specifisity\n",
    "spec=cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8175"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Precision\n",
    "prec=cm[1][1]/(cm[1][1]+cm[0][1])\n",
    "prec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9950874831763122"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recall: Same as Specifisity\n",
    "rec=spec\n",
    "rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8975942127451034"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# F1 Score\n",
    "(2*prec*rec)/(prec+rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# The value of F1 Score on Train data is around 0.89"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Doc_ID</th>\n",
       "      <th>#2016</th>\n",
       "      <th>#?</th>\n",
       "      <th>#??</th>\n",
       "      <th>#affirmation</th>\n",
       "      <th>#affirmations</th>\n",
       "      <th>#allahsoil</th>\n",
       "      <th>#altwaystoheal</th>\n",
       "      <th>#altwaystoheal  #healthy</th>\n",
       "      <th>...</th>\n",
       "      <th>yes</th>\n",
       "      <th>yet</th>\n",
       "      <th>yo</th>\n",
       "      <th>you</th>\n",
       "      <th>you!</th>\n",
       "      <th>you.</th>\n",
       "      <th>you?</th>\n",
       "      <th>young</th>\n",
       "      <th>id</th>\n",
       "      <th>tweet_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 880 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Doc_ID  #2016   #?  #??  #affirmation  #affirmations  \\\n",
       "0  0           1       0.0    0.0  0.0  0.0           0.0             \n",
       "1  1           2       0.0    0.0  0.0  0.0           0.0             \n",
       "2  2           3       0.0    0.0  0.0  0.0           0.0             \n",
       "3  3           4       0.0    0.0  0.0  0.0           0.0             \n",
       "4  4           5       0.0    0.0  0.0  0.0           0.0             \n",
       "\n",
       "   #allahsoil  #altwaystoheal  #altwaystoheal  #healthy  ...  yes  yet   yo  \\\n",
       "0  0.0         0.0             0.0                       ...  0.0  0.0  0.0   \n",
       "1  0.0         0.0             0.0                       ...  0.0  0.0  0.0   \n",
       "2  0.0         1.0             1.0                       ...  0.0  0.0  0.0   \n",
       "3  0.0         0.0             0.0                       ...  1.0  0.0  0.0   \n",
       "4  0.0         0.0             0.0                       ...  0.0  0.0  0.0   \n",
       "\n",
       "   you  you!  you.  you?  young  id  tweet_y  \n",
       "0  0.0  0.0   0.0   0.0   0.0   NaN NaN       \n",
       "1  0.0  0.0   0.0   0.0   0.0   NaN NaN       \n",
       "2  0.0  0.0   0.0   0.0   0.0   NaN NaN       \n",
       "3  0.0  0.0   0.0   0.0   0.0   NaN NaN       \n",
       "4  0.0  0.0   0.0   0.0   0.0   NaN NaN       \n",
       "\n",
       "[5 rows x 880 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets try and calculate the value on test data\n",
    "# importing test_DTM.csv file\n",
    "test_df=pd.read_csv(\"test_DTM.csv\")\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Doc_ID', '#2016', '#?', '#??', '#affirmation',\n",
       "       '#affirmations', '#allahsoil', '#altwaystoheal',\n",
       "       '#altwaystoheal  #healthy',\n",
       "       ...\n",
       "       'yes', 'yet', 'yo', 'you', 'you!', 'you.', 'you?', 'young', 'id',\n",
       "       'tweet_y'],\n",
       "      dtype='object', length=880)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the x_test\n",
    "test_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17197, 875)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing 'Unnamed: 0' and 'Doc_ID' column\n",
    "pos=[i not in ['Unnamed: 0','Doc_ID','dummy','id','label','tweet_y'] for i in test_df.columns ]\n",
    "x_test=test_df[test_df.columns[pos]]\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Running them Model on x_test\n",
    "# Make predictions on the train data set\n",
    "prediction_reg=LogisticRegr.predict(x_test)\n",
    "prediction_reg[0:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "438"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos=[i == 1 for i in prediction_reg]\n",
    "sum(pos) # Total tweets labelled as 1 are 438"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Doc_ID</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Doc_ID  0\n",
       "0  1       0\n",
       "1  2       0\n",
       "2  3       0\n",
       "3  4       0\n",
       "4  5       0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test_complete=pd.concat([test_df['Doc_ID'],pd.DataFrame(list(prediction_reg))],axis=1)\n",
    "Test_complete.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17197, 880)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Doc_ID</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Doc_ID  label\n",
       "0  1       0    \n",
       "1  2       0    \n",
       "2  3       0    \n",
       "3  4       0    \n",
       "4  5       0    "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test_complete.columns=['Doc_ID','label']\n",
    "Test_complete.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label\n",
       "0  0    \n",
       "1  0    \n",
       "2  0    \n",
       "3  0    \n",
       "4  0    "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing the Doc_ID as this is not required for submission\n",
    "Test_complete2=Test_complete.drop(['Doc_ID'],axis=1)\n",
    "Test_complete2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing it back to the folder \n",
    "Test_complete2.to_csv(\"test_predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
